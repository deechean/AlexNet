{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python libs and setup FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters are defined.\n"
     ]
    }
   ],
   "source": [
    "import cifar10\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from AlexNet import alexnet\n",
    "import tf_general as tfg\n",
    "import numpy as np\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "try:\n",
    "    tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "    tf.flags.DEFINE_integer('epoch', 50000, 'epoch')\n",
    "    tf.flags.DEFINE_integer('batch_size', 128, 'batch size')\n",
    "    tf.flags.DEFINE_float('lr', 0.01, 'learning rate')\n",
    "    tf.flags.DEFINE_integer('image_size', 225, 'image size')\n",
    "    tf.flags.DEFINE_integer('test_size', 512, 'test size')\n",
    "    #tf.flags.DEFINE_boolean('restore', False, 'restore from checkpoint and run test')\n",
    "    print('parameters are defined.')\n",
    "except:\n",
    "    print('parameters have been defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data source. \n",
    "The data path is 'cifar-10-batches'. Use distorted_input() to get training data and inputs() to get test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "CONTINUE = 0\n",
    "#第三次微调\n",
    "cifar10_dir='cifar-10-batches' \n",
    "#获取数据增强后的训练集数据\n",
    "train_image, train_label = cifar10.distorted_inputs(cifar10_dir,FLAGS.batch_size, FLAGS.image_size)\n",
    "#获取数据裁剪后的测试数据\n",
    "#test_image, test_label = cifar10.inputs(True, cifar10_dir, FLAGS.test_size, FLAGS.image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    #x = tf.placeholder(tf.float32, [None, 225,225,3], name='input_image')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    global_step = tf.placeholder(tf.int32, name='global_step')\n",
    "    y = train_label\n",
    "    #tf.placeholder(tf.int64, name='input_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define alexnet object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_1:  (128, 225, 225, 3)\n",
      "conv_1:  (128, 54, 54, 96)\n",
      "lrn_1:  (128, 54, 54, 96)\n",
      "pool_1:  (128, 26, 26, 96)\n",
      "conv_2:  (128, 26, 26, 256)\n",
      "lrn_2:  (128, 26, 26, 256)\n",
      "pool_2:  (128, 12, 12, 256)\n",
      "conv_3:  (128, 12, 12, 384)\n",
      "conv_4:  (128, 12, 12, 256)\n",
      "conv_5:  (128, 12, 12, 256)\n",
      "pool_3:  (128, 5, 5, 256)\n",
      "flat_1:  (128, 6400)\n",
      "fc_1:  (128, 4096)\n",
      "fc_2:  (128, 4096)\n",
      "fc_3:  (128, 10)\n",
      "drop_out_1:  (128, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('prediction'):\n",
    "    alex_net = alexnet(train_image, keep_prob)\n",
    "    y_ = alex_net.prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross entropy as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate cross entropy\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_,\n",
    "                           labels=y, name=\"cross_entropy_per_example\")\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "    print('calculate cross entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use optimizer to optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set train step\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('train_step'):\n",
    "    train_step = tf.train.AdagradOptimizer(FLAGS.lr).minimize(cross_entropy)\n",
    "    print('set train step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set accuracy\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_, 1), y), tf.float32))\n",
    "print('set accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model saving path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'ckpt/'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "saver = tf.train.Saver(max_to_keep = 1)\n",
    "coord = tf.train.Coordinator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start session to run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-24 08:01:15 iter:1  4.69%\n",
      "2019-05-24 08:02:00 iter:2  14.06%\n",
      "2019-05-24 08:02:44 iter:3  10.94%\n",
      "2019-05-24 08:03:29 iter:4  14.06%\n",
      "2019-05-24 08:04:14 iter:5  12.5%\n",
      "2019-05-24 08:04:58 iter:6  7.03%\n",
      "2019-05-24 08:05:43 iter:7  10.94%\n",
      "2019-05-24 08:06:28 iter:8  6.25%\n",
      "2019-05-24 08:07:13 iter:9  13.28%\n",
      "2019-05-24 08:07:57 iter:10  11.72%\n",
      "2019-05-24 08:08:42 iter:11  6.25%\n",
      "2019-05-24 08:09:27 iter:12  10.16%\n",
      "2019-05-24 08:10:11 iter:13  7.03%\n",
      "2019-05-24 08:10:56 iter:14  13.28%\n",
      "2019-05-24 08:11:41 iter:15  3.91%\n",
      "2019-05-24 08:12:26 iter:16  10.16%\n"
     ]
    }
   ],
   "source": [
    "import tf_general as tfg\n",
    "import time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if CONTINUE != 0:\n",
    "            model_file=tf.train.latest_checkpoint('ckpt/')\n",
    "            saver.restore(sess, model_file)\n",
    "        threads = tf.train.start_queue_runners(sess, coord)\n",
    "        i = 0\n",
    "        try:\n",
    "            while not coord.should_stop() and i< FLAGS.epoch:\n",
    "                i += 1 \n",
    "                loss,_,accuracy_rate = sess.run([cross_entropy,train_step,accuracy], \n",
    "                                                       feed_dict={keep_prob: 0.5, global_step: i}) \n",
    "                log = []\n",
    "                string = time.strftime(\"%Y-%m-%d %X\",time.localtime())+ ' iter:' + str(i)+'  '+str(round(accuracy_rate*100,2))+ '%'\n",
    "                print(string)\n",
    "                log.append(string)\n",
    "                if (i+1)%250 == 0 and i > 0:\n",
    "                    string = time.strftime(\"%Y-%m-%d %X\",time.localtime())+ ' save model at step '+ str(i) \n",
    "                    print(string)\n",
    "                    log.append(string)\n",
    "                    saver.save(sess,'ckpt/cifar10_'+str(CONTINUE)+'_'+str(i)+'.ckpt',global_step=i)\n",
    "                tfg.saveEvalData('./alexnet_cifar_'+str(CONTINUE)+'.log',log)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            string = time.strftime(\"%Y-%m-%d %X\",time.localtime())+ \" done! now lets kill all the threads……\"\n",
    "            log = []\n",
    "            log.append(string)\n",
    "            tfg.saveEvalData('./alexnet_cifar_'+str(CONTINUE)+'.log',log)\n",
    "        finally:\n",
    "            string = time.strftime(\"%Y-%m-%d %X\",time.localtime()) + \" Finally completed!\"\n",
    "            log = []\n",
    "            log.append(string)\n",
    "            tfg.saveEvalData('./alexnet_cifar_'+str(CONTINUE)+'.log',log)\n",
    "            coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
